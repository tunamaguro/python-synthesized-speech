# General settings.
spk: "jsut"

# exp tag(for managing experiments)
tag:

sample_rate: 16000

# 1) none 2) tqdm
# NOTE: Jupyterノートブックからrun.shを実行する場合は、none推奨
tqdm: tqdm

# Mu-law quantization parameter
mu: 255

# NOTE: benchmarkをtrueにすると、高速化が期待できる分、より多くの
# GPUリソースを必要とする場合があります。
# GPUリソースに余裕がある場合は、true にしてください。
cudnn_benchmark: false
cudnn_deterministic: false

###########################################################
#                DATA PREPARATION SETTING                 #
###########################################################

# PLEASE CHANGE THE PATH BASED ON YOUR ENVIRONMENT
db_root: "downloads/jsut_ver1.1/basic5000"

n_jobs: 4

###########################################################
#                FEATURE EXTRACTION SETTING               #
###########################################################

# HTS-style question used for extracting linguistic contexts
qst_path: "../common/qst1.hed"

###########################################################
#                TRAINING SETTING                         #
###########################################################

duration_model: duration_rnn
logf0_model: logf0_rnn
wavenet_model: wavenet_sr16k_mulaw256

### 継続長モデル & 対数F0予測モデル ###
# エポック数を小さくすると、学習は早く終了します。
dnntts_train_nepochs: 30
# バッチサイズを小さくすると、GPUメモリ使用量が小さく済みます。
dnntts_data_batch_size: 32

### WaveNet ###
# 注意: 50万ステップの学習には数日時間がかかることが予想されます
wavenet_train_max_train_steps: 500000
# 注意: 必要なGPUメモリ（目安）:
# バッチサイズ8の場合に10GB程度、バッチサイズ16の場合に17GB程度
# PyTorch 1.8.1, CUDA 11.2, cuDNN 7.6.3
wavenet_data_batch_size: 16

###########################################################
#                SYNTHESIS SETTING                        #
###########################################################

# リストの逆順で発話を処理する
reverse: false

# 生成する発話の数
# -1 の場合、評価の発話をすべて処理する
# 音声生成にかかる時間を短縮する場合、小さな値（5など）に設定してください
num_eval_utts: -1

duration_eval_checkpoint: latest.pth
logf0_eval_checkpoint: latest.pth
wavenet_eval_checkpoint: latest_ema.pth
